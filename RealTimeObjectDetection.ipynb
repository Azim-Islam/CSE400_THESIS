{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\cheek/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-5-27 Python-3.8.0 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from mss import mss\n",
    "import numpy as np\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model.conf = 0.4\n",
    "model.classes = [2, 3, 4, 5, 6]  \n",
    "sct = mss()\n",
    "\n",
    "xb_min = 290+200\n",
    "xb_max = 1650-200\n",
    "yb_min = 240\n",
    "yb_max = 900\n",
    "while 1:\n",
    "    w, h = 1920, 1080\n",
    "    monitor = {'top': 0, 'left': 0, 'width': w, 'height': h}\n",
    "    img = Image.frombytes('RGB', (w, h), sct.grab(monitor).rgb)\n",
    "    screen = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    # set the model use the screen\n",
    "    result = model(screen, size=1024)\n",
    "    pd = result.pandas().xyxy[0]\n",
    "    \n",
    "    predicted_image = result.render()[0]\n",
    "\n",
    "    for index, row in pd.iterrows():\n",
    "        if True:\n",
    "            xmin = row['xmin']\n",
    "            ymin = row['ymin']\n",
    "            xmax = row['xmax']\n",
    "            ymax = row['ymax']\n",
    "\n",
    "            mid_x = (xmax-xmin)/2 + xmin\n",
    "            mid_y = (ymax-ymin)/2 + ymin\n",
    "            coef = round((xmax-xmin)/(xb_max-xb_min) + (ymax-ymin)/(xb_max-xb_min), 3)\n",
    "            if (xb_min <= mid_x <=  xb_max) and (yb_min <= mid_y <= yb_max) and coef >= 0.39:\n",
    "                cv2.putText(\n",
    "                    img = predicted_image,\n",
    "                    text = f\"WARNING!\",\n",
    "                    org = (int(mid_x), int(mid_y)),\n",
    "                    fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    fontScale = 2,\n",
    "                    color = (0, 10, 240),\n",
    "                    thickness = 3\n",
    "                    )\n",
    "    # predicted_image = cv2.putText(\n",
    "    #         img = predicted_image,\n",
    "    #         text = \"Hello World\",\n",
    "    #         org = (200, 200),\n",
    "    #         fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
    "    #         fontScale = 3.0,\n",
    "    #         color = (125, 246, 55),\n",
    "    #         thickness = 3\n",
    "    #         )\n",
    "    cv2.imshow('Screen', predicted_image)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "model.conf = 0.25  # NMS confidence threshold\n",
    "      iou = 0.45  # NMS IoU threshold\n",
    "      agnostic = False  # NMS class-agnostic\n",
    "      multi_label = False  # NMS multiple labels per box\n",
    "      classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "      max_det = 1000  # maximum number of detections per image\n",
    "      amp = False  # Automatic Mixed Precision (AMP) inference\n",
    "\n",
    "results = model(im, size=320)  # custom inference size\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from mss import mss\n",
    "import numpy as np\n",
    "from torchvision.models.detection import  fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.io.image import read_image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "weights = FasterRCNN_ResNet50_FPN_Weights.COCO_V1\n",
    "model = fasterrcnn_resnet50_fpn(weights=weights)\n",
    "model.eval()\n",
    "sct = mss()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while 1:\n",
    "    w, h = 1920, 1080\n",
    "    monitor = {'top': 0, 'left': 0, 'width': w, 'height': h}\n",
    "    img = Image.frombytes('RGB', (w, h), sct.grab(monitor).rgb)\n",
    "    screen = cv2.cvtColor(np.array(screen), cv2.COLOR_RGB2BGR)\n",
    "    screen = transform(screen)\n",
    "    output = model(screen)\n",
    "    print(output)\n",
    "    # if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "    #     cv2.destroyAllWindows()\n",
    "    #     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import numpy\n",
    "import torch\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from mss import mss\n",
    "\n",
    "\n",
    "\n",
    "coco_names = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(coco_names), 3))\n",
    "sct = mss()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def predict(image, model, device, detection_threshold):\n",
    "    # transform the image to tensor\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0) # add a batch dimension\n",
    "    outputs = model(image) # get the predictions on the image\n",
    "    # print the results individually\n",
    "    # print(f\"BOXES: {outputs[0]['boxes']}\")\n",
    "    # print(f\"LABELS: {outputs[0]['labels']}\")\n",
    "    # print(f\"SCORES: {outputs[0]['scores']}\")\n",
    "    # get all the predicited class names\n",
    "    pred_classes = [coco_names[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
    "    # get score for all the predicted objects\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "    # get all the predicted bounding boxes\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "    # get boxes above the threshold score\n",
    "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
    "    return boxes, pred_classes, outputs[0]['labels']\n",
    "\n",
    "def draw_boxes(boxes, classes, labels, image):\n",
    "    # read the image with OpenCV\n",
    "    image = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2RGB)\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = COLORS[labels[i]]\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 2\n",
    "        )\n",
    "        cv2.putText(image, classes[i], (int(box[0]), int(box[1]-5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, \n",
    "                    lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=1024)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval().to(device)\n",
    "\n",
    "\n",
    "while 1:\n",
    "    w, h = 1920, 1080\n",
    "    monitor = {'top': 0, 'left': 0, 'width': w, 'height': h}\n",
    "    image = Image.frombytes('RGB', (w, h), sct.grab(monitor).rgb)\n",
    "    boxes, classes, labels = predict(image, model, device, 0.8)\n",
    "    image = draw_boxes(boxes, classes, labels, image)\n",
    "    cv2.imshow('Image', image)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training_Scripts-CdYRBVKs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "423a258f591262eab8fd9a5a1a7e88c9a76340757fb6318f0e88361cf770a0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
